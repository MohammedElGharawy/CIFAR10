{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammedElGharawy/CIFAR10/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLzIbFllDTN2",
        "outputId": "0b104499-818e-4faa-8df0-5e260573763a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEGO3-iND4A0",
        "outputId": "49075ec8-4620-42d5-9578-cf4d51296ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "main_dir=\"drive/My Drive/Vision/Image Classification\"#Ahmad\n",
        "os.chdir(main_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-cB9UPKi_uz"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 200\n",
        "data_augmentation = False\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'FOLv6.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c523CJPRLB9N"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floPyPjtjzrZ",
        "outputId": "02e57d9a-3259-4c08-aeaa-0d8397a0bd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK3qm0ZzRrkg"
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yKsNREKkLYz",
        "outputId": "d5106922-fc74-4c7c-8d3f-9ed094b67be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "                \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvIsvhiKkkZC",
        "outputId": "4a3c6a6e-fa32-4d11-edbd-ac19081a9325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 15s 298us/step - loss: 1.9390 - acc: 0.2655 - val_loss: 1.6378 - val_acc: 0.3974\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.6606 - acc: 0.3858 - val_loss: 1.6406 - val_acc: 0.4082\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.5379 - acc: 0.4379 - val_loss: 1.4110 - val_acc: 0.4851\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.4591 - acc: 0.4684 - val_loss: 1.3367 - val_acc: 0.5139\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3914 - acc: 0.4950 - val_loss: 1.3583 - val_acc: 0.5084\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3392 - acc: 0.5179 - val_loss: 1.1909 - val_acc: 0.5688\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.2907 - acc: 0.5346 - val_loss: 1.1586 - val_acc: 0.5770\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.2465 - acc: 0.5518 - val_loss: 1.1414 - val_acc: 0.5883\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.2069 - acc: 0.5657 - val_loss: 1.1439 - val_acc: 0.5887\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.1821 - acc: 0.5782 - val_loss: 1.0661 - val_acc: 0.6179\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.1535 - acc: 0.5857 - val_loss: 1.0863 - val_acc: 0.6111\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.1288 - acc: 0.5944 - val_loss: 1.0242 - val_acc: 0.6362\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.1027 - acc: 0.6056 - val_loss: 1.0121 - val_acc: 0.6385\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.0851 - acc: 0.6143 - val_loss: 1.0743 - val_acc: 0.6190\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.0626 - acc: 0.6216 - val_loss: 0.9806 - val_acc: 0.6509\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0416 - acc: 0.6306 - val_loss: 0.9766 - val_acc: 0.6454\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.0263 - acc: 0.6330 - val_loss: 0.9178 - val_acc: 0.6758\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.0104 - acc: 0.6398 - val_loss: 0.9777 - val_acc: 0.6534\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9891 - acc: 0.6504 - val_loss: 0.9826 - val_acc: 0.6542\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9773 - acc: 0.6542 - val_loss: 0.9253 - val_acc: 0.6687\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9620 - acc: 0.6553 - val_loss: 0.8796 - val_acc: 0.6854\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9533 - acc: 0.6621 - val_loss: 0.8732 - val_acc: 0.6889\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9422 - acc: 0.6652 - val_loss: 0.8502 - val_acc: 0.6959\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9276 - acc: 0.6720 - val_loss: 0.8853 - val_acc: 0.6864\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9149 - acc: 0.6754 - val_loss: 0.8220 - val_acc: 0.7033\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9050 - acc: 0.6788 - val_loss: 0.8105 - val_acc: 0.7131\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8919 - acc: 0.6864 - val_loss: 0.8204 - val_acc: 0.7111\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8852 - acc: 0.6867 - val_loss: 0.8893 - val_acc: 0.6857\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8728 - acc: 0.6901 - val_loss: 0.8347 - val_acc: 0.7025\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8660 - acc: 0.6927 - val_loss: 0.7928 - val_acc: 0.7169\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8526 - acc: 0.6978 - val_loss: 0.7996 - val_acc: 0.7137\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8426 - acc: 0.7014 - val_loss: 0.8249 - val_acc: 0.7075\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.8385 - acc: 0.7019 - val_loss: 0.7769 - val_acc: 0.7262\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.8286 - acc: 0.7085 - val_loss: 0.7704 - val_acc: 0.7281\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8197 - acc: 0.7095 - val_loss: 0.7808 - val_acc: 0.7242\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8077 - acc: 0.7134 - val_loss: 0.7991 - val_acc: 0.7215\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.8071 - acc: 0.7142 - val_loss: 0.7570 - val_acc: 0.7328\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7990 - acc: 0.7168 - val_loss: 0.7474 - val_acc: 0.7367\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7950 - acc: 0.7218 - val_loss: 0.8056 - val_acc: 0.7161\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7885 - acc: 0.7216 - val_loss: 0.7623 - val_acc: 0.7289\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7781 - acc: 0.7255 - val_loss: 0.7338 - val_acc: 0.7435\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7781 - acc: 0.7246 - val_loss: 0.7612 - val_acc: 0.7320\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7716 - acc: 0.7269 - val_loss: 0.7436 - val_acc: 0.7406\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7608 - acc: 0.7296 - val_loss: 0.7446 - val_acc: 0.7418\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.7549 - acc: 0.7349 - val_loss: 0.7189 - val_acc: 0.7491\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.7474 - acc: 0.7347 - val_loss: 0.7207 - val_acc: 0.7455\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7451 - acc: 0.7373 - val_loss: 0.7122 - val_acc: 0.7512\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7357 - acc: 0.7378 - val_loss: 0.7220 - val_acc: 0.7461\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7347 - acc: 0.7406 - val_loss: 0.7765 - val_acc: 0.7296\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7307 - acc: 0.7410 - val_loss: 0.7013 - val_acc: 0.7550\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.7224 - acc: 0.7448 - val_loss: 0.7040 - val_acc: 0.7513\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7199 - acc: 0.7452 - val_loss: 0.7135 - val_acc: 0.7504\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7177 - acc: 0.7474 - val_loss: 0.6900 - val_acc: 0.7564\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7113 - acc: 0.7478 - val_loss: 0.7031 - val_acc: 0.7553\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.7093 - acc: 0.7476 - val_loss: 0.6931 - val_acc: 0.7569\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.7017 - acc: 0.7500 - val_loss: 0.7164 - val_acc: 0.7524\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6991 - acc: 0.7532 - val_loss: 0.7341 - val_acc: 0.7456\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6943 - acc: 0.7539 - val_loss: 0.6836 - val_acc: 0.7603\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6854 - acc: 0.7572 - val_loss: 0.6948 - val_acc: 0.7578\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6891 - acc: 0.7547 - val_loss: 0.6869 - val_acc: 0.7587\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6787 - acc: 0.7592 - val_loss: 0.6737 - val_acc: 0.7649\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6787 - acc: 0.7601 - val_loss: 0.7033 - val_acc: 0.7571\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6750 - acc: 0.7612 - val_loss: 0.6846 - val_acc: 0.7631\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6736 - acc: 0.7628 - val_loss: 0.7015 - val_acc: 0.7562\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6697 - acc: 0.7625 - val_loss: 0.6882 - val_acc: 0.7587\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6600 - acc: 0.7654 - val_loss: 0.6601 - val_acc: 0.7682\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6611 - acc: 0.7666 - val_loss: 0.7189 - val_acc: 0.7528\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6597 - acc: 0.7660 - val_loss: 0.7017 - val_acc: 0.7575\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6518 - acc: 0.7710 - val_loss: 0.7038 - val_acc: 0.7531\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.6513 - acc: 0.7692 - val_loss: 0.6662 - val_acc: 0.7698\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.6470 - acc: 0.7702 - val_loss: 0.6549 - val_acc: 0.7730\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 0.6400 - acc: 0.7737 - val_loss: 0.6649 - val_acc: 0.7658\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6424 - acc: 0.7719 - val_loss: 0.6559 - val_acc: 0.7728\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6331 - acc: 0.7766 - val_loss: 0.6655 - val_acc: 0.7673\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6343 - acc: 0.7768 - val_loss: 0.6563 - val_acc: 0.7723\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6254 - acc: 0.7786 - val_loss: 0.6543 - val_acc: 0.7720\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6229 - acc: 0.7795 - val_loss: 0.6465 - val_acc: 0.7786\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6235 - acc: 0.7789 - val_loss: 0.6897 - val_acc: 0.7620\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6169 - acc: 0.7819 - val_loss: 0.6499 - val_acc: 0.7764\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6113 - acc: 0.7845 - val_loss: 0.6660 - val_acc: 0.7707\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6096 - acc: 0.7848 - val_loss: 0.6408 - val_acc: 0.7781\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6110 - acc: 0.7835 - val_loss: 0.6591 - val_acc: 0.7750\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6088 - acc: 0.7847 - val_loss: 0.6530 - val_acc: 0.7733\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.6062 - acc: 0.7849 - val_loss: 0.6813 - val_acc: 0.7670\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6062 - acc: 0.7862 - val_loss: 0.6751 - val_acc: 0.7703\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.6007 - acc: 0.7862 - val_loss: 0.6324 - val_acc: 0.7783\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.5989 - acc: 0.7880 - val_loss: 0.6453 - val_acc: 0.7770\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5973 - acc: 0.7876 - val_loss: 0.6515 - val_acc: 0.7756\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.5950 - acc: 0.7910 - val_loss: 0.6468 - val_acc: 0.7768\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5889 - acc: 0.7906 - val_loss: 0.6414 - val_acc: 0.7783\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.5883 - acc: 0.7906 - val_loss: 0.6475 - val_acc: 0.7769\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5834 - acc: 0.7933 - val_loss: 0.6434 - val_acc: 0.7797\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5786 - acc: 0.7944 - val_loss: 0.6308 - val_acc: 0.7810\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5747 - acc: 0.7967 - val_loss: 0.6488 - val_acc: 0.7762\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5791 - acc: 0.7941 - val_loss: 0.6417 - val_acc: 0.7792\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5753 - acc: 0.7957 - val_loss: 0.6227 - val_acc: 0.7844\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.5759 - acc: 0.7952 - val_loss: 0.6503 - val_acc: 0.7745\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5737 - acc: 0.7955 - val_loss: 0.6262 - val_acc: 0.7817\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5670 - acc: 0.7984 - val_loss: 0.6283 - val_acc: 0.7849\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5639 - acc: 0.7995 - val_loss: 0.6486 - val_acc: 0.7767\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5645 - acc: 0.7999 - val_loss: 0.6333 - val_acc: 0.7837\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5582 - acc: 0.8016 - val_loss: 0.6844 - val_acc: 0.7703\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5580 - acc: 0.8024 - val_loss: 0.6256 - val_acc: 0.7859\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5517 - acc: 0.8038 - val_loss: 0.6319 - val_acc: 0.7841\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5563 - acc: 0.8033 - val_loss: 0.6825 - val_acc: 0.7654\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5558 - acc: 0.8026 - val_loss: 0.6417 - val_acc: 0.7803\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5507 - acc: 0.8053 - val_loss: 0.6830 - val_acc: 0.7719\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5474 - acc: 0.8066 - val_loss: 0.6459 - val_acc: 0.7794\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5500 - acc: 0.8059 - val_loss: 0.6392 - val_acc: 0.7808\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5442 - acc: 0.8070 - val_loss: 0.6434 - val_acc: 0.7826\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5434 - acc: 0.8074 - val_loss: 0.7091 - val_acc: 0.7642\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5381 - acc: 0.8093 - val_loss: 0.7058 - val_acc: 0.7677\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.5395 - acc: 0.8094 - val_loss: 0.6418 - val_acc: 0.7829\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5408 - acc: 0.8083 - val_loss: 0.6174 - val_acc: 0.7896\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5314 - acc: 0.8125 - val_loss: 0.6261 - val_acc: 0.7873\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5310 - acc: 0.8108 - val_loss: 0.6498 - val_acc: 0.7834\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5347 - acc: 0.8104 - val_loss: 0.6470 - val_acc: 0.7804\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5323 - acc: 0.8109 - val_loss: 0.6381 - val_acc: 0.7830\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5233 - acc: 0.8139 - val_loss: 0.6693 - val_acc: 0.7772\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5223 - acc: 0.8145 - val_loss: 0.6589 - val_acc: 0.7781\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5256 - acc: 0.8150 - val_loss: 0.6224 - val_acc: 0.7881\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5211 - acc: 0.8156 - val_loss: 0.6314 - val_acc: 0.7836\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.5185 - acc: 0.8158 - val_loss: 0.6671 - val_acc: 0.7786\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5163 - acc: 0.8146 - val_loss: 0.6320 - val_acc: 0.7876\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5127 - acc: 0.8181 - val_loss: 0.6243 - val_acc: 0.7903\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.5152 - acc: 0.8166 - val_loss: 0.6310 - val_acc: 0.7866\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5139 - acc: 0.8166 - val_loss: 0.6638 - val_acc: 0.7797\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5128 - acc: 0.8171 - val_loss: 0.6241 - val_acc: 0.7905\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5111 - acc: 0.8188 - val_loss: 0.6330 - val_acc: 0.7882\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5042 - acc: 0.8218 - val_loss: 0.6309 - val_acc: 0.7890\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5053 - acc: 0.8200 - val_loss: 0.6126 - val_acc: 0.7909\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5083 - acc: 0.8191 - val_loss: 0.6160 - val_acc: 0.7931\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.5011 - acc: 0.8212 - val_loss: 0.6270 - val_acc: 0.7886\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5039 - acc: 0.8221 - val_loss: 0.6319 - val_acc: 0.7891\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.5017 - acc: 0.8234 - val_loss: 0.6433 - val_acc: 0.7875\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4903 - acc: 0.8246 - val_loss: 0.6486 - val_acc: 0.7816\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4911 - acc: 0.8260 - val_loss: 0.6553 - val_acc: 0.7809\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4990 - acc: 0.8225 - val_loss: 0.6392 - val_acc: 0.7890\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4964 - acc: 0.8225 - val_loss: 0.6920 - val_acc: 0.7718\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4909 - acc: 0.8258 - val_loss: 0.6522 - val_acc: 0.7858\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4924 - acc: 0.8240 - val_loss: 0.6479 - val_acc: 0.7858\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 0.4887 - acc: 0.8263 - val_loss: 0.6209 - val_acc: 0.7931\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4913 - acc: 0.8236 - val_loss: 0.6239 - val_acc: 0.7931\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4872 - acc: 0.8263 - val_loss: 0.6374 - val_acc: 0.7903\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4858 - acc: 0.8263 - val_loss: 0.6750 - val_acc: 0.7814\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4818 - acc: 0.8293 - val_loss: 0.6231 - val_acc: 0.7968\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4811 - acc: 0.8283 - val_loss: 0.6348 - val_acc: 0.7902\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.4844 - acc: 0.8269 - val_loss: 0.6351 - val_acc: 0.7913\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4816 - acc: 0.8296 - val_loss: 0.6190 - val_acc: 0.7984\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4767 - acc: 0.8308 - val_loss: 0.6259 - val_acc: 0.7941\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4747 - acc: 0.8306 - val_loss: 0.6493 - val_acc: 0.7890\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4748 - acc: 0.8294 - val_loss: 0.6222 - val_acc: 0.7925\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4736 - acc: 0.8316 - val_loss: 0.6265 - val_acc: 0.7952\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4715 - acc: 0.8322 - val_loss: 0.6066 - val_acc: 0.7974\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4700 - acc: 0.8328 - val_loss: 0.6294 - val_acc: 0.7924\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4712 - acc: 0.8331 - val_loss: 0.6117 - val_acc: 0.7967\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4686 - acc: 0.8317 - val_loss: 0.6337 - val_acc: 0.7875\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4670 - acc: 0.8334 - val_loss: 0.6392 - val_acc: 0.7895\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4671 - acc: 0.8342 - val_loss: 0.6413 - val_acc: 0.7854\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4669 - acc: 0.8351 - val_loss: 0.6111 - val_acc: 0.8004\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4700 - acc: 0.8311 - val_loss: 0.6131 - val_acc: 0.7976\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4618 - acc: 0.8351 - val_loss: 0.6356 - val_acc: 0.7949\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4656 - acc: 0.8361 - val_loss: 0.6026 - val_acc: 0.8010\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4654 - acc: 0.8341 - val_loss: 0.6112 - val_acc: 0.7962\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4582 - acc: 0.8369 - val_loss: 0.6034 - val_acc: 0.8011\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4593 - acc: 0.8362 - val_loss: 0.6318 - val_acc: 0.7894\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4575 - acc: 0.8372 - val_loss: 0.6688 - val_acc: 0.7855\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4578 - acc: 0.8381 - val_loss: 0.6155 - val_acc: 0.7958\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4571 - acc: 0.8361 - val_loss: 0.6085 - val_acc: 0.7997\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4547 - acc: 0.8385 - val_loss: 0.6120 - val_acc: 0.7981\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4484 - acc: 0.8399 - val_loss: 0.6302 - val_acc: 0.7955\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4531 - acc: 0.8394 - val_loss: 0.6667 - val_acc: 0.7836\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4565 - acc: 0.8375 - val_loss: 0.6273 - val_acc: 0.7949\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.4504 - acc: 0.8400 - val_loss: 0.6537 - val_acc: 0.7859\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4447 - acc: 0.8402 - val_loss: 0.6312 - val_acc: 0.7937\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4497 - acc: 0.8394 - val_loss: 0.6299 - val_acc: 0.7908\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4514 - acc: 0.8386 - val_loss: 0.6188 - val_acc: 0.7959\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4442 - acc: 0.8438 - val_loss: 0.6322 - val_acc: 0.7978\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4451 - acc: 0.8427 - val_loss: 0.6381 - val_acc: 0.7903\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4454 - acc: 0.8400 - val_loss: 0.6093 - val_acc: 0.8011\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4456 - acc: 0.8422 - val_loss: 0.6126 - val_acc: 0.7993\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4414 - acc: 0.8433 - val_loss: 0.6289 - val_acc: 0.7963\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4449 - acc: 0.8430 - val_loss: 0.6077 - val_acc: 0.7993\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.4411 - acc: 0.8434 - val_loss: 0.6150 - val_acc: 0.7995\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4367 - acc: 0.8434 - val_loss: 0.6083 - val_acc: 0.7998\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4356 - acc: 0.8466 - val_loss: 0.7311 - val_acc: 0.7713\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4360 - acc: 0.8452 - val_loss: 0.6147 - val_acc: 0.7998\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4386 - acc: 0.8448 - val_loss: 0.6094 - val_acc: 0.8013\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4370 - acc: 0.8460 - val_loss: 0.6231 - val_acc: 0.7985\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4332 - acc: 0.8448 - val_loss: 0.6232 - val_acc: 0.7951\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4305 - acc: 0.8453 - val_loss: 0.6518 - val_acc: 0.7918\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4318 - acc: 0.8459 - val_loss: 0.6218 - val_acc: 0.7957\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4340 - acc: 0.8453 - val_loss: 0.6527 - val_acc: 0.7905\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.4341 - acc: 0.8457 - val_loss: 0.6556 - val_acc: 0.7898\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4319 - acc: 0.8461 - val_loss: 0.6135 - val_acc: 0.8019\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4298 - acc: 0.8462 - val_loss: 0.6316 - val_acc: 0.7955\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4269 - acc: 0.8478 - val_loss: 0.6207 - val_acc: 0.8017\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4262 - acc: 0.8478 - val_loss: 0.6355 - val_acc: 0.7955\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.4229 - acc: 0.8483 - val_loss: 0.6586 - val_acc: 0.7913\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.4222 - acc: 0.8495 - val_loss: 0.6253 - val_acc: 0.7983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f508f95ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPjiOgRkmq1w",
        "outputId": "3bdd56cd-fdc8-460d-bb2d-5223f370d571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 155us/step\n",
            "Test loss: 0.6253488616943359\n",
            "Test accuracy: 0.7983\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}